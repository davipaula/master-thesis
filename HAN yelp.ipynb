{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network for Document Classification\n",
    "\n",
    "Use case: predicting Yelp ratings based on review text\n",
    "\n",
    "Taken from: https://github.com/pandeykartikey/Hierarchical-Attention-Network/blob/master/HAN%20yelp.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"  # check with nvidia-smi\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset is taken from https://github.com/justmarkham/DAT7/blob/master/data/yelp.csv \n",
    "df = pd.read_csv('/Volumes/data/repo/data/yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of data for local development\n",
    "df = df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mark the columns which contains text for classification and target class\n",
    "col_text = 'text'\n",
    "col_target = 'cool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available label class 14\n"
     ]
    }
   ],
   "source": [
    "cls_arr = np.sort(df[col_target].unique()).tolist()\n",
    "classes = len(cls_arr)\n",
    "\n",
    "print(f'Available label class {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide dataset in 80% train 10% validation 10% test as done in the paper\n",
    "length = df.shape[0]\n",
    "train_len = int(0.8*length)\n",
    "val_len = int(0.1*length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:train_len]\n",
    "val = df[train_len:train_len+val_len]\n",
    "test = df[train_len+val_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string, max_seq_len):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = BeautifulSoup(string, \"lxml\").text\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\\"\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\\"s\", \" \\\"s\", string)\n",
    "    string = re.sub(r\"\\\"ve\", \" \\\"ve\", string)\n",
    "    string = re.sub(r\"n\\\"t\", \" n\\\"t\", string)\n",
    "    string = re.sub(r\"\\\"re\", \" \\\"re\", string)\n",
    "    string = re.sub(r\"\\\"d\", \" \\\"d\", string)\n",
    "    string = re.sub(r\"\\\"ll\", \" \\\"ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    s =string.strip().lower().split(\" \")\n",
    "    if len(s) > max_seq_len:\n",
    "        return s[0:max_seq_len] \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a 3D list of format paragraph[sentence[word]]\n",
    "def create3DList(df,col, max_sent_len,max_seq_len):\n",
    "    x=[]\n",
    "    for docs in df[col].as_matrix():\n",
    "        x1=[]\n",
    "        idx = 0\n",
    "        for seq in \"|||\".join(re.split(\"[.?!]\", docs)).split(\"|||\"):\n",
    "            x1.append(clean_str(seq,max_sent_len))\n",
    "            if(idx>=max_seq_len-1):\n",
    "                break\n",
    "            idx= idx+1\n",
    "        x.append(x1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix the maximum length of sentences in a paragraph and words in a sentence\n",
    "max_sent_len = 12\n",
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maos01/miniconda3/envs/smash-rnn/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 400\n",
      "x_val: 50\n",
      "x_test: 50\n"
     ]
    }
   ],
   "source": [
    "## divides review in sentences and sentences into word creating a 3DList\n",
    "x_train = create3DList(train,col_text, max_sent_len,max_seq_len)\n",
    "x_val = create3DList(val, col_text, max_sent_len,max_seq_len)\n",
    "x_test = create3DList(test, col_text, max_sent_len,max_seq_len)\n",
    "print(\"x_train: {}\".format(len(x_train)))\n",
    "print(\"x_val: {}\".format(len(x_val)))\n",
    "print(\"x_test: {}\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.summarization.textcleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english') + list(string.punctuation)\n",
    "stemmer = SnowballStemmer('english')\n",
    "x_train_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_train]\n",
    "x_test_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_test]\n",
    "x_val_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_val]\n",
    "\n",
    "## calculate frequency of words\n",
    "from collections import defaultdict\n",
    "frequency1 = defaultdict(int)\n",
    "for texts in x_train_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_test_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_val_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "            \n",
    "## remove  words with frequency less than 5.\n",
    "x_train_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_train_texts]\n",
    "\n",
    "x_test_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_test_texts]\n",
    "x_val_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(more_itertools.collapse(x_train_texts[:] + x_test_texts[:] + x_val_texts[:],levels=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:collected 730 word types from a corpus of 15737 raw words and 5620 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 retains 730 unique words (100% of original 730, drops 0)\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 leaves 15737 word corpus (100% of original 15737, drops 0)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 730 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 74 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 12771 word corpus (81.2% of prior 15737)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 730 words and 200 dimensions: 1533000 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 3 workers on 730 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 15737 raw words (12749 effective words) took 0.0s, 853872 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 15737 raw words (12827 effective words) took 0.0s, 1116595 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 15737 raw words (12756 effective words) took 0.0s, 1161661 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 15737 raw words (12808 effective words) took 0.0s, 1041659 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 15737 raw words (12789 effective words) took 0.0s, 878985 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 78685 raw words (63929 effective words) took 0.1s, 639828 effective words/s\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "## train word2vec model on all the words\n",
    "word2vec = Word2Vec(texts,size=200, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Word2Vec object under dictonary_yelp, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "INFO:gensim.utils:saved dictonary_yelp\n"
     ]
    }
   ],
   "source": [
    "word2vec.save(\"dictonary_yelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert 3D text list to 3D list of index \n",
    "x_train_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maos01/miniconda3/envs/smash-rnn/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weights = torch.FloatTensor(word2vec.wv.syn0)  #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 730\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2vec.wv.vocab)\n",
    "\n",
    "print(f'vocab_size = {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[col_target].tolist()\n",
    "y_test = test[col_target].tolist()\n",
    "y_val = val[col_target].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the the multiple attention with word vectors.\n",
    "def attention_mul(rnn_outputs, att_weights):\n",
    "    attn_vectors = None\n",
    "    for i in range(rnn_outputs.size(0)):\n",
    "        h_i = rnn_outputs[i]\n",
    "        a_i = att_weights[i]\n",
    "        h_i = a_i * h_i\n",
    "        h_i = h_i.unsqueeze(0)\n",
    "        if(attn_vectors is None):\n",
    "            attn_vectors = h_i\n",
    "        else:\n",
    "            attn_vectors = torch.cat((attn_vectors,h_i),0)\n",
    "    return torch.sum(attn_vectors, 0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The word RNN model for generating a sentence vector\n",
    "class WordRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedsize, batch_size, hid_size):\n",
    "        super(WordRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        ## Word Encoder\n",
    "        self.embed = nn.Embedding(vocab_size, embedsize)\n",
    "        self.wordRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Word Attention\n",
    "        self.wordattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "    def forward(self,inp, hid_state):\n",
    "        emb_out  = self.embed(inp)\n",
    "\n",
    "        out_state, hid_state = self.wordRNN(emb_out, hid_state)\n",
    "\n",
    "        word_annotation = self.wordattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(word_annotation),dim=1)\n",
    "\n",
    "        sent = attention_mul(out_state,attn)\n",
    "        return sent, hid_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The HAN model\n",
    "class SentenceRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedsize, batch_size, hid_size,c):\n",
    "        super(SentenceRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        self.cls = c\n",
    "        self.wordRNN = WordRNN(vocab_size,embedsize, batch_size, hid_size)\n",
    "        ## Sentence Encoder\n",
    "        self.sentRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Sentence Attention\n",
    "        self.sentattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "        self.doc_linear = nn.Linear(2*hid_size, c)\n",
    "    \n",
    "    def forward(self,inp, hid_state_sent, hid_state_word):\n",
    "        s = None\n",
    "        ## Generating sentence vector through WordRNN\n",
    "        for i in range(len(inp[0])):\n",
    "            r = None\n",
    "            for j in range(len(inp)):\n",
    "                if(r is None):\n",
    "                    r = [inp[j][i]]\n",
    "                else:\n",
    "                    r.append(inp[j][i])\n",
    "            r1 = np.asarray([sub_list + [0] * (max_seq_len - len(sub_list)) for sub_list in r])\n",
    "            _s, state_word = self.wordRNN(torch.LongTensor(r1).view(-1,batch_size), hid_state_word)\n",
    "            if(s is None):\n",
    "                s = _s\n",
    "            else:\n",
    "                s = torch.cat((s,_s),0)\n",
    "\n",
    "                out_state, hid_state = self.sentRNN(s, hid_state_sent)\n",
    "        sent_annotation = self.sentattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(sent_annotation),dim=1)\n",
    "\n",
    "        doc = attention_mul(out_state,attn)\n",
    "        d = self.doc_linear(doc)\n",
    "        cls = F.log_softmax(d.view(-1,self.cls),dim=1)\n",
    "        return cls, hid_state\n",
    "    \n",
    "    def init_hidden_sent(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size)) #.cuda()\n",
    "    \n",
    "    def init_hidden_word(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size)) #.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting list to tensor\n",
    "y_train_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_train]\n",
    "y_val_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_val]\n",
    "y_test_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)])\n",
    "max_sent_len = max([len(sent) for sent in (x_train_vec + x_val_vec + x_test_vec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)]),90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(sent) for sent in (x_train_vec +x_val_vec + x_test_vec)]),90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding the input \n",
    "X_train_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_train_vec]\n",
    "X_val_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_val_vec]\n",
    "X_test_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_test_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 #64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 100\n",
    "embedsize = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_attn = SentenceRNN(vocab_size,embedsize,batch_size,hid_size,classes)\n",
    "#sent_attn.cuda()\n",
    "sent_attn.wordRNN.embed.from_pretrained(weights)\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "sent_optimizer = torch.optim.SGD(sent_attn.parameters(), lr=learning_rate, momentum= momentum)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(x,y,batch_size):\n",
    "    k = random.sample(range(len(x)-1),batch_size)\n",
    "    x_batch=[]\n",
    "    y_batch=[]\n",
    "\n",
    "    for t in k:\n",
    "        x_batch.append(x[t])\n",
    "        y_batch.append(y[t])\n",
    "\n",
    "    return [x_batch,y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(batch_size, x_val,y_val,sent_attn_model):\n",
    "    acc = []\n",
    "    val_length = len(x_val)\n",
    "    for j in range(int(val_length/batch_size)):\n",
    "        x,y = gen_batch(x_val,y_val,batch_size)\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        \n",
    "        y_pred, state_sent = sent_attn_model(x, state_sent, state_word)\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(y)).sum()\n",
    "        acc.append(float(correct)/batch_size)\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at 0 paragraphs, 1 epoch,(0m 0s) is 2.837280\n",
      "Accuracy at 0 paragraphs, 1 epoch,(0m 0s) is 0.000000\n",
      "Loss at 48 paragraphs, 1 epoch,(0m 2s) is 1.726979\n",
      "Accuracy at 48 paragraphs, 1 epoch,(0m 2s) is 0.500000\n",
      "Loss at 96 paragraphs, 1 epoch,(0m 5s) is 1.730285\n",
      "Accuracy at 96 paragraphs, 1 epoch,(0m 5s) is 0.567308\n",
      "Loss at 144 paragraphs, 1 epoch,(0m 7s) is 1.596561\n",
      "Accuracy at 144 paragraphs, 1 epoch,(0m 7s) is 0.546053\n",
      "Loss at 192 paragraphs, 1 epoch,(0m 10s) is 1.607676\n",
      "Accuracy at 192 paragraphs, 1 epoch,(0m 10s) is 0.560000\n",
      "Loss at 240 paragraphs, 1 epoch,(0m 12s) is 1.519780\n",
      "Accuracy at 240 paragraphs, 1 epoch,(0m 12s) is 0.584677\n",
      "Loss at 288 paragraphs, 1 epoch,(0m 15s) is 1.488606\n",
      "Accuracy at 288 paragraphs, 1 epoch,(0m 15s) is 0.587838\n",
      "Loss at 336 paragraphs, 1 epoch,(0m 17s) is 1.488588\n",
      "Accuracy at 336 paragraphs, 1 epoch,(0m 17s) is 0.575581\n",
      "Loss at 384 paragraphs, 1 epoch,(0m 20s) is 1.461833\n",
      "Accuracy at 384 paragraphs, 1 epoch,(0m 20s) is 0.586735\n",
      "Loss after 1 epoch,(0m 20s) is 1.455359\n",
      "Train Accuracy after 1 epoch,(0m 20s) is 0.590000\n",
      "Validation Accuracy after 1 epoch,(0m 21s) is 0.666667\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train_pad\n",
    "y_train = y_train_tensor\n",
    "x_val = X_val_pad\n",
    "y_val = y_val_tensor\n",
    "sent_attn_optimiser = sent_optimizer\n",
    "sent_attn_model = sent_attn\n",
    "loss_criterion = criterion\n",
    "print_loss_every = 50\n",
    "code_test=True\n",
    "\n",
    "start = time.time()\n",
    "loss_full = []\n",
    "loss_epoch = []\n",
    "acc_epoch = []\n",
    "acc_full = []\n",
    "val_acc = []\n",
    "epoch_counter = 0\n",
    "train_length = len(x_train)\n",
    "for i in range(1, num_epoch + 1):\n",
    "    loss_epoch = []\n",
    "    acc_epoch = []\n",
    "    for j in range(int(train_length/batch_size)):\n",
    "        review, targets = gen_batch(x_train,y_train,batch_size)\n",
    "\n",
    "        #loss,acc = train_data(batch_size, x, y, sent_attn_model, sent_attn_optimiser, loss_criterion)\n",
    "        #def train_data(batch_size, review, targets, sent_attn_model, sent_optimizer, criterion):\n",
    "\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        sent_attn_optimiser.zero_grad()\n",
    "\n",
    "        y_pred, state_sent = sent_attn_model(review, state_sent, state_word)\n",
    "\n",
    "        loss = loss_criterion(y_pred, torch.LongTensor(targets)) \n",
    "\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(targets)).sum()\n",
    "        acc = float(correct)/batch_size\n",
    "\n",
    "        loss.backward()\n",
    "        sent_optimizer.step()\n",
    "\n",
    "        loss = loss.data.item()\n",
    "\n",
    "        loss_epoch.append(loss)\n",
    "        acc_epoch.append(acc)\n",
    "        if (code_test and j % int(print_loss_every/batch_size) == 0) :\n",
    "            print ('Loss at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(loss_epoch)))\n",
    "            print ('Accuracy at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(acc_epoch)))\n",
    "\n",
    "    loss_full.append(np.mean(loss_epoch))\n",
    "    acc_full.append(np.mean(acc_epoch))\n",
    "    torch.save(sent_attn_model.state_dict(), 'sent_attn_model_yelp.pth')\n",
    "    print ('Loss after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(loss_epoch)))\n",
    "    print ('Train Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(acc_epoch)))\n",
    "\n",
    "    val_acc.append(validation_accuracy(batch_size, x_val, y_val, sent_attn_model)) \n",
    "    print ('Validation Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), val_acc[-1]))\n",
    "    #return loss_full,acc_full,val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_full)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAWbElEQVR4nO3df7BfdX3n8efLIIiiEiVlkUSCilOhIspddt1qp2pR7O4GK46AHTUqw6BN2bFL2+xouy7WWcG621XZqSmLpR2VKKttGLdipFrXrdbcSEQDIiHqkIjrBcQuotDAe//4ngvfXM69nCT33O/35j4fM2e+3/M5P+77kzuT1z3nc36kqpAkaabHjLoASdJ4MiAkSa0MCElSKwNCktTKgJAktTpk1AXMl6OOOqpWr1496jIkaVHZunXrHVW1om3ZQRMQq1evZnJyctRlSNKikuT7sy3zFJMkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWvUaEEnOSHJzkh1J1rcsX5tkKsm2ZjqvaX/JUNu2JD9P8qo+a5Uk7e2QvnacZBlwGXA6sAvYkmRTVd04Y9WNVbVuuKGqvgCc0uznKcAO4HN91SpJeqQ+jyBOA3ZU1c6quh+4CjhzP/bzGuBvqureea1OkjSnPgPiWOC2ofldTdtMZyW5IcnVSVa1LD8H+HjbD0hyfpLJJJNTU1MHXrEk6SGjHqS+BlhdVScDm4ErhxcmOQZ4LnBt28ZVtaGqJqpqYsWKFb0XK0lLSZ8BsRsYPiJY2bQ9pKrurKr7mtnLgVNn7OO1wKer6p96q1KS1KrPgNgCnJDk+CSHMjhVtGl4heYIYdoa4KYZ+ziXWU4vSZL61dtVTFW1J8k6BqeHlgFXVNX2JBcDk1W1CbgwyRpgD3AXsHZ6+ySrGRyB/F1fNUqSZpeqGnUN82JiYqImJydHXYYkLSpJtlbVRNuyUQ9SS5LGlAEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIkloZEJKkVgaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWvUaEEnOSHJzkh1J1rcsX5tkKsm2ZjpvaNnTk3wuyU1Jbkyyus9aJUl7O6SvHSdZBlwGnA7sArYk2VRVN85YdWNVrWvZxV8A76mqzUmOAB7sq1ZJ0iP1eQRxGrCjqnZW1f3AVcCZXTZMciJwSFVtBqiqe6rq3v5KlSTN1GdAHAvcNjS/q2mb6awkNyS5Osmqpu3ZwN1JPpXk+iTva45I9pLk/CSTSSanpqbmvweStISNepD6GmB1VZ0MbAaubNoPAV4MXAT8c+AZwNqZG1fVhqqaqKqJFStWLEzFkrREPGpAJNmY5BVJso/73g2sGppf2bQ9pKrurKr7mtnLgVOb77uAbc3pqT3AXwEv2MefL0k6AF2OID4CvBn4TpI/SvKsjvveApyQ5PgkhwLnAJuGV0hyzNDsGuCmoW2PTDJ9WPBSYObgtiSpR48aEFX12ao6m8Gg8w+BLyT5UpLXJ5n1KqjmL/91wLUM/uP/RFVtT3JxkjXNahcm2Z7kG8CFNKeRquoBBqeXrkvyTSDAn+13LyVJ+yxV9egrJcuB1wFvAO4APga8CDihqn6t1wo7mpiYqMnJyVGXIUmLSpKtVTXRtuxR74NI8kngucBHgbOqalez6KNJrp+/MiVJ46TLjXIbgM9Xy6FGVT1//kuSJI2DLoPUzwSePD2TZHmS8/srSZI0DroExAVVdff0TFX9GHhrfyVJksZBl4DY6w7mJI8BHttPOZKkcdFlDGJzko8Df9rMXwB8vr+SJEnjoEtA/C7wNuDtzfxm4MO9VSRJGguPGhDNTWsfbCZJ0hLR5T6IZwLvAU4EHjfdXlXP7rEuSdKIdRmk/nMGz2MK8ErgE8DGHmuSJI2BLgHx+Kq6FqCqbq2qdzIICknSQazLIPV9zaWttya5gMEju5/Yb1mSpFHrEhBvB57A4Gmr7wGexODx35Kkg9icAdG85vM3quofgP8HvH5BqpIkjdycYxDNJa4vWaBaJEljpMsppq1JPgV8EvjpdGNVbZp9E0nSYtclIJ7IIBh+faitmPH6UEnSwaXLndSOO0jSEtTlTuoNbe1V5TshJOkg1uUU03VD3x8H/AZwWz/lSJLGRZdTTHs9ViPJXwJf7q0iSdJY6PKojZmOB46e70IkSeOlyxjEjxlctQSDQLkLWN9nUZKk0esyBnHU0PcHq6pmXVOSdNDocorpXwNHVNUDVVVJjkzyb/ouTJI0Wl0C4uKq+sn0TFXdDby7v5IkSeOgS0Ckpa3LqSlJ0iLWJSCuT3JpkuOa6X3A9V12nuSMJDcn2ZHkEQPbSdYmmUqyrZnOG1r2wFC7j/WQpAXW5UhgHfAu4K8ZXM20GXjbo23UPCr8MuB0YBewJcmmqrpxxqobq2pdyy5+VlWndKhPktSDLjfK3QNctB/7Pg3YUVU7AZJcBZwJzAwISdIYetRTTEk+m+TIofnlST7TYd/HsvcjOXY1bTOdleSGJFcnWTXU/rgkk0m+muRVs9R2frPO5NTUVIeSJElddRmDOLq5cgmAqvox8LR5+vnXAKur6mQGp66uHFp2XFVNAK8D/iTJM2duXFUbqmqiqiZWrFgxTyVJkqBbQDyYZOX0TJKnd9z3bmD4iGBl0/aQqrqzqu5rZi8HTh1atrv53Al8EXh+x58rSZoHXQLiD4H/k+QjSf4c+BLwjg7bbQFOSHJ8kkOBc5jxkqEkxwzNrgFuatqXJzms+X4U8Ms4diFJC6rLIPVnkpwGvLBp+r2q+lGH7fYkWQdcCywDrqiq7UkuBiabV5ZemGQNsIfBM57WNps/B/hwkgcZhNh7W65+kiT1KPvyaKUkq4FzgXOq6nk91bRfJiYmanJyctRlSNKikmRrM977CF2uYjo6yW8n+QrwbeDxPPyXviTpIDVrQCR5c5LNwN8zuDz1t4Dbq+oPqqrTndSSpMVrrjGIDzMIh9dMB0ISH/UtSUvEXAFxLPBa4ENJlgMbgccuSFWSpJGb9RRTVf2oqj5UVb8MvBL4OXBnkm82VyJJkg5ind5JXVXfr6pLmofnnd1zTZKkMbDP73Vo7kf4wx5qkSSNkU5HEJKkpceAkCS1etRTTElObmn+CXBbVT04/yVJksZBlzGI/wGcAmxn8H7q5zB4cN4Tk5xfVdf1WJ8kaUS6nGL6HnBqVZ3SPH/pVOA7wCuA9/dYmyRphLoExHOq6obpmar6JnBiVe3oryxJ0qh1OcX07SQfBK5q5s9u2g5j8JhuSdJBqMsRxBsYvE96fTP9AHgjg3B4WX+lSZJGqcsLg+4FLmmmmX4y7xVJksZCl8tc/yXwH4Hjhtevqmf3WJckacS6jEF8BPg9YCvwQL/lSJLGRZeA+Mequqb3SiRJY6VLQPxtkv8MfAq4b7px+NJXSdLBp0tAvGjGJ0ABvzL/5UiSxkWXq5hevBCFSJLGy6wBkeTcqvp4kgvbllfVB/orS5I0anMdQSxvPlcsRCGSpPEya0BU1X9vPv9g4cqRJI2LLjfKHQW8GVjN3jfKnd9fWZKkUetyFdNfA18Fvow3yknSktElIJ5QVf9+f3ae5AzgvwHLgMur6r0zlq8F3gfsbpo+VFWXDy1/EoOXE/1VVa3bnxokSfuny9Nc/ybJy/d1x0mWAZcBrwROBM5NcmLLqhublxGdMhwOjXcDX9rXny1JOnBdAuIC4LNJ7klyV5IfJ7mrw3anATuqamdV3c/gfRJndi0syanA0cDnum4jSZo/XQLiKOCxwJMZXPJ6FN0ufT0WuG1oflfTNtNZSW5IcnWSVQBJHsPgdaYXzfUDkpyfZDLJ5NTUVIeSJEldzRoQSU5ovp40yzQfrgFWV9XJwGbgyqb9bcD/qqpdc21cVRuqaqKqJlas8HYNSZpPcw1SrwfewmAcYaYuz2LaDawaml/Jw4PRg51U3Tk0ezlwafP9hcCLk7wNOAI4NMk9VbX+UX6mJGmezHWj3Fuaz/19FtMW4IQkxzMIhnOA1w2vkOSYqrq9mV0D3NT8zN8cWmctMGE4SNLC6nKZK0l+kcGVSI+bbquqj821TVXtSbIOuJbBZa5XVNX2JBcDk1W1CbgwyRoG77e+C1i7X72QJM27VNXcKyTvBF4O/CKD/+xfAXy5ql7df3ndTUxM1OTk5KjLkKRFJcnWqppoW9blKqazgZcAt1fV64HnAU+Yx/okSWOoS0D8rKoeAPYkeSLwQ+C4fsuSJI1alzGI65McCVwBTAL/CHyt16okSSM3Z0AkCfCuqrobuCzJtcCTqurrC1KdJGlk5gyIqqokm4FfauZ3LEhVkqSR6zIGsS3J83uvRJI0VuZ6J/UhVbUHeD6wJcmtwE+BMDi4eMEC1ShJGoG5TjF9DXgBgzucJUlLzFwBEYCqunWBapEkjZG5AmJFkt+ZbWFV/Zce6pEkjYm5AmIZgyepZoFqkSSNkbkC4vaqunjBKpEkjZW5LnP1yEGSlrC5AuJlC1aFJGnszBoQVXXXQhYiSRovXe6kliQtQQaEJKmVASFJamVASJJaGRCSpFYGhCSplQEhSWplQEiSWhkQkqRWBoQkqZUBIUlqZUBIklr1GhBJzkhyc5IdSda3LF+bZCrJtmY6r2k/LsnXm7btSS7os05J0iPN9cKgA5JkGXAZcDqwC9iSZFNV3Thj1Y1VtW5G2+3AC6vqviRHAN9qtv1BX/VKkvbW5xHEacCOqtpZVfcDVwFndtmwqu6vqvua2cPwVJgkLbg+/+M9FrhtaH5X0zbTWUluSHJ1klXTjUlWJbmh2cclbUcPSc5PMplkcmpqar7rl6QlbdR/mV8DrK6qk4HNwJXTC6rqtqb9WcAbkxw9c+Oq2lBVE1U1sWLFigUrWpKWgj4DYjewamh+ZdP2kKq6c+hU0uXAqTN30hw5fAt4cU91SpJa9BkQW4ATkhyf5FDgHGDT8ApJjhmaXQPc1LSvTHJ483058CLg5h5rlSTN0NtVTFW1J8k64FpgGXBFVW1PcjEwWVWbgAuTrAH2AHcBa5vNnwO8P0kBAf64qr7ZV62SpEdKVY26hnkxMTFRk5OToy5DkhaVJFuraqJt2agHqSVJY8qAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa0MCElSKwNCktTKgJAktTIgJEmtDAhJUisDQpLUyoCQJLUyICRJrQwISVIrA0KS1MqAkCS1MiAkSa16DYgkZyS5OcmOJOtblq9NMpVkWzOd17SfkuQrSbYnuSHJ2X3WKUl6pEP62nGSZcBlwOnALmBLkk1VdeOMVTdW1boZbfcCb6iqW5I8Ddia5NqquruveiVJe+vzCOI0YEdV7ayq+4GrgDO7bFhV36mqW5rvPwB+BKzorVJJ0iP0GRDHArcNze9q2mY6qzmNdHWSVTMXJjkNOBS4tWXZ+Ukmk0xOTU3NV92SJEY/SH0NsLqqTgY2A1cOL0xyDPCXwJuq6sGZG1fVhqqaqKqJFSs8wJCk+dRnQOwGho8IVjZtD6mqO6vqvmb2cuDU6WVJngR8BnhHVX21xzolSS36DIgtwAlJjk9yKHAOsGl4heYIYdoa4Kam/VDg08BfVNXVPdYoSZpFb1cxVdWeJOuAa4FlwBVVtT3JxcBkVW0CLkyyBtgD3AWsbTZ/LfArwFOTTLetraptfdUrSdpbqmrUNcyLiYmJmpycHHUZkrSoJNlaVRNty0Y9SC1JGlMGhCSplQEhSWplQEiSWh00g9RJpoDvj7qO/XAUcMeoi1hg9nlpsM+Lw3FV1Xqn8UETEItVksnZriA4WNnnpcE+L36eYpIktTIgJEmtDIjR2zDqAkbAPi8N9nmRcwxCktTKIwhJUisDQpLUyoBYAEmekmRzkluaz+WzrPfGZp1bkryxZfmmJN/qv+IDdyB9TvL4JJ9J8u0k25O8d2Gr7y7JGUluTrIjyfqW5Ycl2dgs/4ckq4eW/Yem/eYkr1jIug/E/vY5yelJtib5ZvP50oWufX8dyO+5Wf70JPckuWihap4XVeXU8wRcCqxvvq8HLmlZ5ynAzuZzefN9+dDyVwMfA7416v703Wfg8cBLmnUOBf438MpR96ml/mUMXoX7jKbObwAnzljnbcCfNt/PATY2309s1j8MOL7Zz7JR96nnPj8feFrz/ZeA3aPuT999Hlp+NfBJ4KJR92dfJo8gFsaZPPw61SuBV7Ws8wpgc1XdVVU/ZvAK1jMAkhwB/A7wRwtQ63zZ7z5X1b1V9QWAqrof+DqDNxKOm9OAHVW1s6nzKgb9Hjb873A18LIkadqvqqr7quq7wI5mf+Nuv/tcVddX1Q+a9u3A4UkOW5CqD8yB/J5J8irguwz6vKgYEAvj6Kq6vfn+Q+DolnWOBW4bmt/VtAG8G3g/cG9vFc6/A+0zAEmOBP4tcF0fRR6gR61/eJ2q2gP8BHhqx23H0YH0edhZwNfr4VcOj7P97nPzx93vA/9pAeqcd729UW6pSfJ54J+1LHrH8ExVVZLO1xYnOQV4ZlW9feZ5zVHrq89D+z8E+DjwgarauX9VatwkOQm4BHj5qGtZAO8C/mtV3dMcUCwqBsQ8qapfm21Zkv+b5Jiqur15D/ePWlbbDfzq0PxK4IvAC4GJJN9j8Pv6hSRfrKpfZcR67PO0DcAtVfUn81BuH3YDq4bmVzZtbevsagLvycCdHbcdRwfSZ5KsZPC++TdU1a39lzsvDqTP/wJ4TZJLgSOBB5P8vKo+1H/Z82DUgyBLYQLex94Dtpe2rPMUBucplzfTd4GnzFhnNYtnkPqA+sxgvOV/Ao8ZdV/m6OMhDAbWj+fhwcuTZqzzW+w9ePmJ5vtJ7D1IvZPFMUh9IH0+sln/1aPux0L1ecY672KRDVKPvIClMDE4/3odcAvw+aH/BCeAy4fWezODwcodwJta9rOYAmK/+8zgL7QCbgK2NdN5o+7TLP38deA7DK5yeUfTdjGwpvn+OAZXr+wAvgY8Y2jbdzTb3cwYXqU1330G3gn8dOh3ug34hVH3p+/f89A+Fl1A+KgNSVIrr2KSJLUyICRJrQwISVIrA0KS1MqAkCS1MiCkfZDkgSTbhqZHPNnzAPa9erE8rVdLg3dSS/vmZ1V1yqiLkBaCRxDSPEjyvSSXNu86+FqSZzXtq5P8bZIbklyX5OlN+9FJPp3kG830r5pdLUvyZ817MD6X5PCRdUpLngEh7ZvDZ5xiOnto2U+q6rnAh4Dp50d9ELiyqk4GPgp8oGn/APB3VfU84AU8/CjoE4DLquok4G4GTz2VRsI7qaV9kOSeqjqipf17wEurameSxwI/rKqnJrkDOKaq/qlpv72qjkoyBaysocddN0/r3VxVJzTzvw88tqoW03tAdBDxCEKaPzXL930x/H6EB3CcUCNkQEjz5+yhz6803/+ewdM9AX6TwetTYfAgw7cCJFmW5MkLVaTUlX+dSPvm8CTbhuY/W1XTl7ouT3IDg6OAc5u23wY+kuR3gSngTU37vwM2JHkLgyOFtwK3I40RxyCkedCMQUxU1R2jrkWaL55ikiS18ghCktTKIwhJUisDQpLUyoCQJLUyICRJrQwISVKr/w9TtA+iiaVqcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_full)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('train_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_acc)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('val_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(batch_size, x_test, y_test, sent_attn_model):\n",
    "    acc = []\n",
    "    test_length = len(x_test)\n",
    "    for j in range(int(test_length/batch_size)):\n",
    "        x,y = gen_batch(x_test,y_test,batch_size)\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        \n",
    "        y_pred, state_sent = sent_attn_model(x, state_sent, state_word)\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(y)).sum()\n",
    "        acc.append(float(correct)/batch_size)\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(batch_size, X_test_pad, y_test_tensor, sent_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2275, -3.4169, -2.2838, -4.1196, -4.0289, -5.0914, -4.4849, -5.2996,\n",
       "         -6.0842, -5.8064, -6.3291, -6.2725, -6.0226, -6.9623],\n",
       "        [-0.2012, -3.5427, -2.3386, -4.2325, -4.2303, -5.2892, -4.7342, -5.5522,\n",
       "         -6.3163, -5.9588, -6.5203, -6.4650, -6.2449, -7.2799],\n",
       "        [-0.2175, -3.4632, -2.3050, -4.1733, -4.0259, -5.1096, -4.6232, -5.5055,\n",
       "         -6.1655, -5.8857, -6.4031, -6.3844, -6.1270, -7.1166],\n",
       "        [-0.1903, -3.6379, -2.3731, -4.2567, -4.2564, -5.3318, -4.7867, -5.6472,\n",
       "         -6.4332, -6.1202, -6.6738, -6.6105, -6.3810, -7.3687],\n",
       "        [-0.2179, -3.4775, -2.3185, -4.0793, -4.0529, -5.1230, -4.5835, -5.4399,\n",
       "         -6.1950, -5.8615, -6.3195, -6.3247, -6.0813, -7.0201],\n",
       "        [-0.2118, -3.5120, -2.2839, -4.1932, -4.1864, -5.2037, -4.6829, -5.5380,\n",
       "         -6.3105, -5.9990, -6.4613, -6.4698, -6.2174, -7.1968],\n",
       "        [-0.2071, -3.5241, -2.3177, -4.2043, -4.1522, -5.2243, -4.7124, -5.5513,\n",
       "         -6.2936, -5.9852, -6.4985, -6.4650, -6.2326, -7.2036],\n",
       "        [-0.1849, -3.6554, -2.3725, -4.3692, -4.3203, -5.4213, -4.8456, -5.6957,\n",
       "         -6.5273, -6.1634, -6.7153, -6.7070, -6.4763, -7.4625]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict only a single batch\n",
    "\n",
    "x, y = gen_batch(X_test_pad,y_test_tensor,batch_size)\n",
    "\n",
    "state_word = sent_attn.init_hidden_word()\n",
    "state_sent = sent_attn.init_hidden_sent()\n",
    "    \n",
    "y_pred, state_sent = sent_attn(x, state_sent, state_word)\n",
    "y_pred  # probability per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index = y_pred.max(dim = 1)[1]  # use label with highest probability as prediction\n",
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.]),\n",
       " tensor([1.]),\n",
       " tensor([1.]),\n",
       " tensor([0.]),\n",
       " tensor([5.]),\n",
       " tensor([0.]),\n",
       " tensor([4.]),\n",
       " tensor([0.])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y  # true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 14])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape # torch.Size([batch_size=8, labels=14]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
