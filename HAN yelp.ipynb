{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Attention Network for Document Classification\n",
    "\n",
    "Use case: predicting Yelp ratings based on review text\n",
    "\n",
    "Taken from: https://github.com/pandeykartikey/Hierarchical-Attention-Network/blob/master/HAN%20yelp.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"  # check with nvidia-smi\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The dataset is taken from https://github.com/justmarkham/DAT7/blob/master/data/yelp.csv \n",
    "df = pd.read_csv('./input/yelp/yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of data for local development\n",
    "df = df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mark the columns which contains text for classification and target class\n",
    "col_text = 'text'\n",
    "col_target = 'cool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available label class 14\n"
     ]
    }
   ],
   "source": [
    "cls_arr = np.sort(df[col_target].unique()).tolist()\n",
    "classes = len(cls_arr)\n",
    "\n",
    "print(f'Available label class {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide dataset in 80% train 10% validation 10% test as done in the paper\n",
    "length = df.shape[0]\n",
    "train_len = int(0.8*length)\n",
    "val_len = int(0.1*length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:train_len]\n",
    "val = df[train_len:train_len+val_len]\n",
    "test = df[train_len+val_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string, max_seq_len):\n",
    "    \"\"\"\n",
    "    adapted from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = BeautifulSoup(string, \"lxml\").text\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\\"\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\\"s\", \" \\\"s\", string)\n",
    "    string = re.sub(r\"\\\"ve\", \" \\\"ve\", string)\n",
    "    string = re.sub(r\"n\\\"t\", \" n\\\"t\", string)\n",
    "    string = re.sub(r\"\\\"re\", \" \\\"re\", string)\n",
    "    string = re.sub(r\"\\\"d\", \" \\\"d\", string)\n",
    "    string = re.sub(r\"\\\"ll\", \" \\\"ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    s =string.strip().lower().split(\" \")\n",
    "    if len(s) > max_seq_len:\n",
    "        return s[0:max_seq_len] \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creates a 3D list of format paragraph[sentence[word]]\n",
    "def create3DList(df,col, max_sent_len,max_seq_len):\n",
    "    x=[]\n",
    "    for docs in df[col].as_matrix():\n",
    "        x1=[]\n",
    "        idx = 0\n",
    "        for seq in \"|||\".join(re.split(\"[.?!]\", docs)).split(\"|||\"):\n",
    "            x1.append(clean_str(seq,max_sent_len))\n",
    "            if(idx>=max_seq_len-1):\n",
    "                break\n",
    "            idx= idx+1\n",
    "        x.append(x1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix the maximum length of sentences in a paragraph and words in a sentence\n",
    "max_sent_len = 12\n",
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 400\n",
      "x_val: 50\n",
      "x_test: 50\n"
     ]
    }
   ],
   "source": [
    "## divides review in sentences and sentences into word creating a 3DList\n",
    "x_train = create3DList(train,col_text, max_sent_len,max_seq_len)\n",
    "x_val = create3DList(val, col_text, max_sent_len,max_seq_len)\n",
    "x_test = create3DList(test, col_text, max_sent_len,max_seq_len)\n",
    "print(\"x_train: {}\".format(len(x_train)))\n",
    "print(\"x_val: {}\".format(len(x_val)))\n",
    "print(\"x_test: {}\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dnascimentodepau/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english') + list(string.punctuation)\n",
    "stemmer = SnowballStemmer('english')\n",
    "x_train_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_train]\n",
    "x_test_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_test]\n",
    "x_val_texts = [[[stemmer.stem(word.lower()) for word in sent  if word not in stoplist] for sent in para]\n",
    "         for para in x_val]\n",
    "\n",
    "## calculate frequency of words\n",
    "from collections import defaultdict\n",
    "frequency1 = defaultdict(int)\n",
    "for texts in x_train_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_test_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "for texts in x_val_texts:     \n",
    "    for text in texts:\n",
    "        for token in text:\n",
    "            frequency1[token] += 1\n",
    "            \n",
    "## remove  words with frequency less than 5.\n",
    "x_train_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_train_texts]\n",
    "\n",
    "x_test_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_test_texts]\n",
    "x_val_texts = [[[token for token in text if frequency1[token] > 5]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(more_itertools.collapse(x_train_texts[:] + x_test_texts[:] + x_val_texts[:],levels=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:collected 730 word types from a corpus of 15737 raw words and 5620 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 retains 730 unique words (100% of original 730, drops 0)\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 leaves 15737 word corpus (100% of original 15737, drops 0)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 730 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 74 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 12771 word corpus (81.2% of prior 15737)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 730 words and 200 dimensions: 1533000 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 3 workers on 730 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 15737 raw words (12749 effective words) took 0.0s, 1462361 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 15737 raw words (12827 effective words) took 0.0s, 1184854 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 15737 raw words (12756 effective words) took 0.0s, 1035849 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 15737 raw words (12808 effective words) took 0.0s, 937799 effective words/s\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 15737 raw words (12789 effective words) took 0.0s, 904093 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 78685 raw words (63929 effective words) took 0.1s, 618081 effective words/s\n",
      "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "## train word2vec model on all the words\n",
    "word2vec = Word2Vec(texts,size=200, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Word2Vec object under dictonary_yelp, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "INFO:gensim.utils:saved dictonary_yelp\n"
     ]
    }
   ],
   "source": [
    "word2vec.save(\"dictonary_yelp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert 3D text list to 3D list of index \n",
    "x_train_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_vec = [[[word2vec.wv.vocab[token].index for token in text]\n",
    "         for text in texts] for texts in x_val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weights = torch.FloatTensor(word2vec.wv.syn0)  #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size = 730\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2vec.wv.vocab)\n",
    "\n",
    "print(f'vocab_size = {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[col_target].tolist()\n",
    "y_test = test[col_target].tolist()\n",
    "y_val = val[col_target].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the the multiple attention with word vectors.\n",
    "def attention_mul(rnn_outputs, att_weights):\n",
    "    attn_vectors = None\n",
    "    for i in range(rnn_outputs.size(0)):\n",
    "        h_i = rnn_outputs[i]\n",
    "        a_i = att_weights[i]\n",
    "        h_i = a_i * h_i\n",
    "        h_i = h_i.unsqueeze(0)\n",
    "        if(attn_vectors is None):\n",
    "            attn_vectors = h_i\n",
    "        else:\n",
    "            attn_vectors = torch.cat((attn_vectors,h_i),0)\n",
    "    return torch.sum(attn_vectors, 0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The word RNN model for generating a sentence vector\n",
    "class WordRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedsize, batch_size, hid_size):\n",
    "        super(WordRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        ## Word Encoder\n",
    "        self.embed = nn.Embedding(vocab_size, embedsize)\n",
    "        self.wordRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Word Attention\n",
    "        self.wordattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "    def forward(self,inp, hid_state):\n",
    "        emb_out  = self.embed(inp)\n",
    "\n",
    "        out_state, hid_state = self.wordRNN(emb_out, hid_state)\n",
    "\n",
    "        word_annotation = self.wordattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(word_annotation),dim=1)\n",
    "\n",
    "        sent = attention_mul(out_state,attn)\n",
    "        return sent, hid_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The HAN model\n",
    "class SentenceRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedsize, batch_size, hid_size,c):\n",
    "        super(SentenceRNN, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.embedsize = embedsize\n",
    "        self.hid_size = hid_size\n",
    "        self.cls = c\n",
    "        self.wordRNN = WordRNN(vocab_size,embedsize, batch_size, hid_size)\n",
    "        ## Sentence Encoder\n",
    "        self.sentRNN = nn.GRU(embedsize, hid_size, bidirectional=True)\n",
    "        ## Sentence Attention\n",
    "        self.sentattn = nn.Linear(2*hid_size, 2*hid_size)\n",
    "        self.attn_combine = nn.Linear(2*hid_size, 2*hid_size,bias=False)\n",
    "        self.doc_linear = nn.Linear(2*hid_size, c)\n",
    "    \n",
    "    def forward(self,inp, hid_state_sent, hid_state_word):\n",
    "        s = None\n",
    "        ## Generating sentence vector through WordRNN\n",
    "        for i in range(len(inp[0])):\n",
    "            r = None\n",
    "            for j in range(len(inp)):\n",
    "                if(r is None):\n",
    "                    r = [inp[j][i]]\n",
    "                else:\n",
    "                    r.append(inp[j][i])\n",
    "            r1 = np.asarray([sub_list + [0] * (max_seq_len - len(sub_list)) for sub_list in r])\n",
    "            _s, state_word = self.wordRNN(torch.LongTensor(r1).view(-1,batch_size), hid_state_word)\n",
    "            if(s is None):\n",
    "                s = _s\n",
    "            else:\n",
    "                s = torch.cat((s,_s),0)\n",
    "\n",
    "                out_state, hid_state = self.sentRNN(s, hid_state_sent)\n",
    "        sent_annotation = self.sentattn(out_state)\n",
    "        attn = F.softmax(self.attn_combine(sent_annotation),dim=1)\n",
    "\n",
    "        doc = attention_mul(out_state,attn)\n",
    "        d = self.doc_linear(doc)\n",
    "        cls = F.log_softmax(d.view(-1,self.cls),dim=1)\n",
    "        return cls, hid_state\n",
    "    \n",
    "    def init_hidden_sent(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size)) #.cuda()\n",
    "    \n",
    "    def init_hidden_word(self):\n",
    "            return Variable(torch.zeros(2, self.batch_size, self.hid_size)) #.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting list to tensor\n",
    "y_train_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_train]\n",
    "y_val_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_val]\n",
    "y_test_tensor =  [torch.FloatTensor([cls_arr.index(label)]) for label in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)])\n",
    "max_sent_len = max([len(sent) for sent in (x_train_vec + x_val_vec + x_test_vec)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(seq) for seq in itertools.chain.from_iterable(x_train_vec +x_val_vec + x_test_vec)]),90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array([len(sent) for sent in (x_train_vec +x_val_vec + x_test_vec)]),90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding the input \n",
    "X_train_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_train_vec]\n",
    "X_val_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_val_vec]\n",
    "X_test_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_test_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 #64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 100\n",
    "embedsize = 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_attn = SentenceRNN(vocab_size,embedsize,batch_size,hid_size,classes)\n",
    "#sent_attn.cuda()\n",
    "sent_attn.wordRNN.embed.from_pretrained(weights)\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "sent_optimizer = torch.optim.SGD(sent_attn.parameters(), lr=learning_rate, momentum= momentum)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-150-a86c82c71dfe>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-150-a86c82c71dfe>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    return '%dm %ds' % (m, s)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60## Padding the input \n",
    "X_train_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_train_vec]\n",
    "X_val_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_val_vec]\n",
    "X_test_pad = [sub_list + [[0]] * (max_sent_len - len(sub_list)) for sub_list in x_test_vec]\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(x,y,batch_size):\n",
    "    k = random.sample(range(len(x)-1),batch_size)\n",
    "    x_batch=[]\n",
    "    y_batch=[]\n",
    "\n",
    "    for t in k:\n",
    "        x_batch.append(x[t])\n",
    "        y_batch.append(y[t])\n",
    "\n",
    "    return [x_batch,y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(batch_size, x_val,y_val,sent_attn_model):\n",
    "    acc = []\n",
    "    val_length = len(x_val)\n",
    "    for j in range(int(val_length/batch_size)):\n",
    "        x,y = gen_batch(x_val,y_val,batch_size)\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        \n",
    "        y_pred, state_sent = sent_attn_model(x, state_sent, state_word)\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(y)).sum()\n",
    "        acc.append(float(correct)/batch_size)\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train_pad\n",
    "y_train = y_train_tensor\n",
    "x_val = X_val_pad\n",
    "y_val = y_val_tensor\n",
    "sent_attn_optimiser = sent_optimizer\n",
    "sent_attn_model = sent_attn\n",
    "loss_criterion = criterion\n",
    "print_loss_every = 50\n",
    "code_test=True\n",
    "\n",
    "start = time.time()\n",
    "loss_full = []\n",
    "loss_epoch = []\n",
    "acc_epoch = []\n",
    "acc_full = []\n",
    "val_acc = []\n",
    "epoch_counter = 0\n",
    "train_length = len(x_train)\n",
    "for i in range(1, num_epoch + 1):\n",
    "    loss_epoch = []\n",
    "    acc_epoch = []\n",
    "    for j in range(int(train_length/batch_size)):\n",
    "        review, targets = gen_batch(x_train,y_train,batch_size)\n",
    "\n",
    "        #loss,acc = train_data(batch_size, x, y, sent_attn_model, sent_attn_optimiser, loss_criterion)\n",
    "        #def train_data(batch_size, review, targets, sent_attn_model, sent_optimizer, criterion):\n",
    "\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        sent_attn_optimiser.zero_grad()\n",
    "\n",
    "        y_pred, state_sent = sent_attn_model(review, state_sent, state_word)\n",
    "\n",
    "        loss = loss_criterion(y_pred, torch.LongTensor(targets)) \n",
    "\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(targets)).sum()\n",
    "        acc = float(correct)/batch_size\n",
    "\n",
    "        loss.backward()\n",
    "        sent_optimizer.step()\n",
    "\n",
    "        loss = loss.data.item()\n",
    "\n",
    "        loss_epoch.append(loss)\n",
    "        acc_epoch.append(acc)\n",
    "        if (code_test and j % int(print_loss_every/batch_size) == 0) :\n",
    "            print ('Loss at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(loss_epoch)))\n",
    "            print ('Accuracy at %d paragraphs, %d epoch,(%s) is %f' %(j*batch_size, i, timeSince(start), np.mean(acc_epoch)))\n",
    "\n",
    "    loss_full.append(np.mean(loss_epoch))\n",
    "    acc_full.append(np.mean(acc_epoch))\n",
    "    torch.save(sent_attn_model.state_dict(), 'sent_attn_model_yelp.pth')\n",
    "    print ('Loss after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(loss_epoch)))\n",
    "    print ('Train Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), np.mean(acc_epoch)))\n",
    "\n",
    "    val_acc.append(validation_accuracy(batch_size, x_val, y_val, sent_attn_model)) \n",
    "    print ('Validation Accuracy after %d epoch,(%s) is %f' %(i, timeSince(start), val_acc[-1]))\n",
    "    #return loss_full,acc_full,val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_full)\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_full)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('train_acc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_acc)\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.savefig('val_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(batch_size, x_test, y_test, sent_attn_model):\n",
    "    acc = []\n",
    "    test_length = len(x_test)\n",
    "    for j in range(int(test_length/batch_size)):\n",
    "        x,y = gen_batch(x_test,y_test,batch_size)\n",
    "        state_word = sent_attn_model.init_hidden_word()\n",
    "        state_sent = sent_attn_model.init_hidden_sent()\n",
    "        \n",
    "        y_pred, state_sent = sent_attn_model(x, state_sent, state_word)\n",
    "        max_index = y_pred.max(dim = 1)[1]\n",
    "        correct = (max_index == torch.LongTensor(y)).sum()\n",
    "        acc.append(float(correct)/batch_size)\n",
    "    return np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(batch_size, X_test_pad, y_test_tensor, sent_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1741, -4.0062, -2.6549, -3.6691, -2.7616, -3.3027, -2.4295, -2.0877,\n",
       "         -3.9228, -1.8919, -2.2334, -2.3381, -3.0652, -2.1960],\n",
       "        [-3.1976, -4.0816, -2.6940, -3.6914, -2.7765, -3.2747, -2.3692, -2.1019,\n",
       "         -3.9383, -1.8936, -2.2065, -2.3057, -3.0684, -2.2297],\n",
       "        [-3.2069, -4.0158, -2.6660, -3.6645, -2.7948, -3.2461, -2.3859, -2.1162,\n",
       "         -3.9439, -1.8842, -2.2229, -2.3358, -3.0429, -2.2096],\n",
       "        [-3.2413, -4.0920, -2.7189, -3.6842, -2.8085, -3.2874, -2.3531, -2.0771,\n",
       "         -3.9690, -1.8625, -2.2220, -2.3315, -3.0824, -2.2115],\n",
       "        [-3.2305, -4.0712, -2.7202, -3.7067, -2.8083, -3.2799, -2.3620, -2.0719,\n",
       "         -3.9839, -1.8699, -2.2454, -2.3341, -3.0796, -2.1772],\n",
       "        [-3.2601, -4.1050, -2.7153, -3.7070, -2.7870, -3.3295, -2.3478, -2.0704,\n",
       "         -3.9988, -1.8475, -2.2405, -2.3340, -3.1226, -2.1898],\n",
       "        [-3.1799, -3.9644, -2.6413, -3.7790, -2.7501, -3.2800, -2.4294, -2.1109,\n",
       "         -3.8886, -1.8648, -2.2054, -2.3831, -3.0499, -2.2136],\n",
       "        [-3.1946, -4.0581, -2.6699, -3.7293, -2.7563, -3.2916, -2.3822, -2.1042,\n",
       "         -3.9330, -1.8507, -2.2128, -2.3620, -3.1138, -2.2193]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict only a single batch\n",
    "\n",
    "x, y = gen_batch(X_test_pad,y_test_tensor,batch_size)\n",
    "\n",
    "state_word = sent_attn.init_hidden_word()\n",
    "state_sent = sent_attn.init_hidden_sent()\n",
    "    \n",
    "y_pred, state_sent = sent_attn(x, state_sent, state_word)\n",
    "y_pred  # probability per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 9, 9, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index = y_pred.max(dim = 1)[1]  # use label with highest probability as prediction\n",
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.]),\n",
       " tensor([7.]),\n",
       " tensor([0.]),\n",
       " tensor([0.]),\n",
       " tensor([3.]),\n",
       " tensor([0.]),\n",
       " tensor([0.]),\n",
       " tensor([0.])]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y  # true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 14])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape # torch.Size([batch_size=8, labels=14]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
