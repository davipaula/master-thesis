{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YELP Siamese: A little example of a LSTM-Siamese for Text Similarity\n",
    "\n",
    "Positive ratings are similar to each other! Negative too ;)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- PackedSequence: https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 1\n",
    "learning_rate = 2e-5\n",
    "max_seq_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and preprocess it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The dataset is taken from https://github.com/justmarkham/DAT7/blob/master/data/yelp.csv \n",
    "df = pd.read_csv('/Volumes/data/repo/data/yelp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4481</th>\n",
       "      <td>noLH_u4MJzfXYYHqcByjnA</td>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>ja8Up9t41UlbF2eXNSuabA</td>\n",
       "      <td>4</td>\n",
       "      <td>We just moved to town and were looking for a p...</td>\n",
       "      <td>review</td>\n",
       "      <td>SgjR6pUm_mpmX0f-XH1Ztw</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>W34RE9avBNLfkmiiZwPKiA</td>\n",
       "      <td>2009-06-24</td>\n",
       "      <td>K7N-DrWgKiYySwHfP3sf8A</td>\n",
       "      <td>5</td>\n",
       "      <td>Agree with the previous review. Something nice...</td>\n",
       "      <td>review</td>\n",
       "      <td>UPtysDF6cUDUxq2KY-6Dcg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>T1EfT96sCrn_UUWQMhzB5w</td>\n",
       "      <td>2011-10-31</td>\n",
       "      <td>UMjqZj-SJ25VnLyB3EV4ug</td>\n",
       "      <td>3</td>\n",
       "      <td>A coyote ugly knock off but a cool place. The ...</td>\n",
       "      <td>review</td>\n",
       "      <td>4E_nPWw89FLFHdNsEgMH-g</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "4481  noLH_u4MJzfXYYHqcByjnA  2010-07-01  ja8Up9t41UlbF2eXNSuabA      4   \n",
       "3840  W34RE9avBNLfkmiiZwPKiA  2009-06-24  K7N-DrWgKiYySwHfP3sf8A      5   \n",
       "9946  T1EfT96sCrn_UUWQMhzB5w  2011-10-31  UMjqZj-SJ25VnLyB3EV4ug      3   \n",
       "\n",
       "                                                   text    type  \\\n",
       "4481  We just moved to town and were looking for a p...  review   \n",
       "3840  Agree with the previous review. Something nice...  review   \n",
       "9946  A coyote ugly knock off but a cool place. The ...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  positive  negative  \n",
       "4481  SgjR6pUm_mpmX0f-XH1Ztw     1       2      0         1         0  \n",
       "3840  UPtysDF6cUDUxq2KY-6Dcg     1       0      1         1         0  \n",
       "9946  4E_nPWw89FLFHdNsEgMH-g     1       1      4         1         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make it a 2D classification!\n",
    "df['positive'] = 0\n",
    "df['negative'] = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    df.at[idx, 'positive'] = 1 if row['stars'] >= 3 else 0\n",
    "    df.at[idx, 'negative'] = 1 if row['stars'] <= 2 else 0\n",
    "    \n",
    "df.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8000\n",
      "Test: 2000\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "split_at = int(0.8 * len(df))\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_df = df[:split_at]\n",
    "test_df = df[split_at:]\n",
    "\n",
    "print(f'Train: {len(train_df)}')\n",
    "print(f'Test: {len(test_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very good food! We ate some shrimp tacos and macaroni and cheese. They split our tacos up for us and didn't charge for it...the portions were great too!\r\n",
      "\r\n",
      "Our server was friendly as well. Would definitely return!\n"
     ]
    }
   ],
   "source": [
    "# Print some example review text\n",
    "t = df['text'][0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy is used to tokenize the review texts\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.utils_any2vec:loading projection weights from /Volumes/data/repo/data/glove.6B/glove.6B.200d.w2vformat.txt\n",
      "INFO:gensim.models.utils_any2vec:loaded (400000, 200) matrix from /Volumes/data/repo/data/glove.6B/glove.6B.200d.w2vformat.txt\n"
     ]
    }
   ],
   "source": [
    "# We use Glove word embeddings\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('/Volumes/data/repo/data/glove.6B/glove.6B.200d.w2vformat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2ed1af59954f4e8f950ed2cadeedd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data loader from df\n",
    "\n",
    "idx2token_ids = {}\n",
    "idx2len = {}\n",
    "idx2y = {}\n",
    "\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    # Tokenize text and convert to word2vec idxs\n",
    "    doc = nlp(row['text'])\n",
    "    token_ids = []\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            word = token.norm_\n",
    "            if word in w2v_model.vocab:\n",
    "                token_ids.append(w2v_model.vocab[word].index)  # TODO: Add special index for UNKNOWN + PADDING\n",
    "        break  # For now we only use the first sentence\n",
    "\n",
    "    #train_token_ids.append(torch.tensor(token_ids))\n",
    "    #train_y.append([row['positive']]) # , row['negative']\n",
    "    length = min(len(token_ids), max_seq_length)  # not larger than max length\n",
    "    if length > 2:\n",
    "        idx2token_ids[idx] = torch.tensor(token_ids)\n",
    "        idx2y[idx] = row['positive']\n",
    "        idx2len[idx] = length\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs: 77,246\n"
     ]
    }
   ],
   "source": [
    "# For siamese nets we need pair-wise data\n",
    "\n",
    "n_pairs = 10  # n * n would be too much - keep it at n * 10\n",
    "\n",
    "idxs = list(idx2y.keys())\n",
    "\n",
    "train_token_ids_a = []\n",
    "train_token_len_a = []\n",
    "\n",
    "train_token_ids_b = []\n",
    "train_token_len_b = []\n",
    "\n",
    "train_y = []\n",
    "\n",
    "for a_idx in idx2y:\n",
    "    for b_idx in random.sample(idxs, n_pairs):\n",
    "        if a_idx != b_idx:\n",
    "            if idx2y[a_idx] == idx2y[b_idx]:\n",
    "                train_y.append(1)  # similar\n",
    "            else:\n",
    "                train_y.append(0)  # not similar\n",
    "                \n",
    "            train_token_ids_a.append(idx2token_ids[a_idx])\n",
    "            train_token_ids_b.append(idx2token_ids[b_idx])\n",
    "\n",
    "            train_token_len_a.append(idx2len[a_idx])\n",
    "            train_token_len_b.append(idx2len[b_idx])\n",
    "            \n",
    "            \n",
    "            \n",
    "print(f'Training pairs: {len(train_y):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([191, 219, 565, 805])\n",
      "tensor([  41,   33,   51,    4,   13, 2029, 5447,    2])\n",
      "1\n",
      "----\n",
      "tensor([191, 219, 565, 805])\n",
      "tensor([12910,   285,     3,     0,   795,  1152,    13, 68229,    11,   793,\n",
      "         9119,     2])\n",
      "1\n",
      "----\n",
      "tensor([191, 219, 565, 805])\n",
      "tensor([  61,   41,  809,   77, 1095,   10, 3330,   22,   37, 2551,   22,    0,\n",
      "         156,    3,  478,    1,   41, 5572,   20,  100,  181,   12,   41,  116,\n",
      "           7, 3611, 1812,    4, 2432,  645,  168,    2])\n",
      "1\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Print some examples\n",
    "for i in range(3):\n",
    "    print(train_token_ids_a[i])\n",
    "    print(train_token_ids_b[i])\n",
    "    print(train_y[i])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77246"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(train_token_ids_a) == len(train_token_ids_b) \n",
    "assert len(train_token_ids_a) == len(train_y)\n",
    "assert len(train_token_ids_a) == len(train_token_len_b)\n",
    "assert len(train_token_len_a) == len(train_token_len_b)\n",
    "\n",
    "len(train_token_ids_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([77246, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add padding + limit to max length\n",
    "\n",
    "# , padding_value=0\n",
    "train_idxs_pad_a = pad_sequence(train_token_ids_a, batch_first=True)[:,:max_seq_length]\n",
    "train_idxs_pad_b = pad_sequence(train_token_ids_b, batch_first=True)[:,:max_seq_length]\n",
    "\n",
    "train_idxs_pad_a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data loader\n",
    "train_dataset = TensorDataset(\n",
    "    train_idxs_pad_a, torch.tensor(train_token_len_a),\n",
    "    train_idxs_pad_b, torch.tensor(train_token_len_b),\n",
    "    torch.tensor(train_y)\n",
    ")  #  dtype=torch.float\n",
    "\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "#train_sampler = SequentialSampler(train_dataset)  # only to debugging (real training should be random)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size) #, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseSentenceLSTM(nn.Module):\n",
    "    def __init__(self, embedding_layer, embed_dim, hidden_dim, batch_size, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim        \n",
    "        self.embed = embedding_layer\n",
    "        \n",
    "        self.n_layers = 1\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = False\n",
    "        self.directions = 2 if self.bidirectional else 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embed_dim, \n",
    "            hidden_size=self.hidden_dim, \n",
    "            num_layers=1, \n",
    "            bidirectional=self.bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.input_dim = int(5 * self.directions * self.hidden_dim)\n",
    "        self.mlp_dim = int(self.input_dim/2)\n",
    "        \n",
    "        self.out_dim = out_dim  # depends on how many labels we have (binary => dim = 1)\n",
    "\n",
    "        self.classifier = nn.Sequential(  # two layers (maybe add more?)\n",
    "            nn.Linear(self.input_dim, self.mlp_dim),\n",
    "            nn.Linear(self.mlp_dim, self.out_dim)\n",
    "        )\n",
    "        \n",
    "        self.prob = nn.Sigmoid()  # or softmax?\n",
    "        \n",
    "    def init_hidden_cell(self):\n",
    "        \"\"\"\n",
    "        h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2, else it should be 1.\n",
    "\n",
    "        c_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial cell state for each element in the batch.\n",
    "\n",
    "        If (h_0, c_0) is not provided, both h_0 and c_0 default to zero.\n",
    "\n",
    "        \"\"\"\n",
    "            \n",
    "        # zero or random initialization\n",
    "        # https://r2rt.com/non-zero-initial-states-for-recurrent-neural-networks.html\n",
    "        \n",
    "        rand_hidden = Variable(torch.randn(self.directions * self.n_layers, self.batch_size, self.hidden_dim))\n",
    "        rand_cell = Variable(torch.randn(self.directions * self.n_layers, self.batch_size, self.hidden_dim))\n",
    "        \n",
    "        return rand_hidden, rand_cell\n",
    "    \n",
    "    def forward(self, sent1, len1, sent2, len2):\n",
    "\n",
    "        # init hidden, cell\n",
    "        h1, c1 = self.init_hidden_cell()\n",
    "        h2, c2 = self.init_hidden_cell()\n",
    "\n",
    "        # input one by one\n",
    "        #for i in range(len(s1)):\n",
    "        #    v1, h1, c1 = self.encoder(s1[i], h1, c1)\n",
    "        \n",
    "        # batch-wise: pack padded sequences (required for RNNs, other padding zeros will be evaluated)\n",
    "        packed_output1, (h1, c1) = self.lstm(\n",
    "            pack_padded_sequence(self.embed(sent1), len1, batch_first=True, enforce_sorted=False),\n",
    "            (h1, c1)\n",
    "        )\n",
    "        \n",
    "        packed_output2, (h2, c2) = self.lstm(\n",
    "            pack_padded_sequence(self.embed(sent2), len2, batch_first=True, enforce_sorted=False),\n",
    "            (h2, c2)\n",
    "        )\n",
    "        \n",
    "        # unpack sequences\n",
    "        output_padded1, output_lengths1 = pad_packed_sequence(packed_output1, batch_first=True)\n",
    "        output_padded2, output_lengths2 = pad_packed_sequence(packed_output2, batch_first=True)\n",
    "        \n",
    "        # last word output\n",
    "        #v1 = output_padded1[:,-1]\n",
    "        #v2 = output_padded2[:,-1]\n",
    "        \n",
    "        # last hidden state (dim = batch_size x hidden_dim)\n",
    "        v1 = h1[-1]\n",
    "        v2 = h2[-1]\n",
    "        \n",
    "\n",
    "        # utilize these two encoded vectors\n",
    "        #features = torch.cat((v1,torch.abs(v1 - v2),v2,v1*v2, (v1+v2)/2), 2)\n",
    "        features = torch.cat((v1,torch.abs(v1 - v2),v2,v1*v2, (v1+v2)/2), dim=1)\n",
    "        \n",
    "        # run classical MLP on combined vectors\n",
    "        output = self.classifier(features)\n",
    "        \n",
    "        # convert into 0-1 interval\n",
    "        prob_out = self.prob(output)\n",
    "\n",
    "        return prob_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_weights = torch.FloatTensor(w2v_model.vectors)  # load Glove embeddings\n",
    "    \n",
    "# Initialize model with our settings\n",
    "model = SiameseSentenceLSTM(\n",
    "    embedding_layer=nn.Embedding.from_pretrained(w2v_weights),\n",
    "    embed_dim=w2v_model.vector_size,\n",
    "    hidden_dim=100,\n",
    "    batch_size=batch_size,\n",
    "    out_dim=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea01a4aa95ba4f31a7cdb671ddc17722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 1/3', max=7725, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0 loss: 0.5849032521170706\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c6c8fd6b86473abb78d7e243474fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 2/3', max=7725, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1 loss: 0.5738093224891181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61011760e705478195914d1fd3abf6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch: 3/3', max=7725, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2 loss: 0.5689087561534832\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=learning_rate)  # maybe try different optimizer and loss function?\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# actual training loop\n",
    "for epoch_num in range(epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    # iterate over each batch\n",
    "    for step_num, batch_data in enumerate(tqdm(train_dataloader, desc=f'Epoch: {epoch_num + 1}/{epochs}')):\n",
    "        \n",
    "        # switch model to training mode, clear gradient accumulators\n",
    "        model.train()\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # in case GPU is enabled, this sends data to GPU\n",
    "        sent1, len1, sent2, len2, y = tuple(t.to(device) for t in batch_data) \n",
    "        \n",
    "        # predict\n",
    "        probas = model(sent1, len1, sent2, len2)  \n",
    "\n",
    "        # for CrossEntropyLoss you must use .squeeze()\n",
    "        batch_loss = criterion(probas.squeeze(), y.float())  # loss function\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "        # backpropagate and update optimizer learning rate\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'\\r{epoch_num} loss: {train_loss / (step_num + 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4497.900374084711"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO visualize training progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173ca87ae4ec44a78a024163c85d8de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Evaluate', max=7725, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "all_y = None\n",
    "all_probas = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step_num, batch_data in enumerate(tqdm(train_dataloader, desc=f'Evaluate')):  # evaluate on TRAIN for debugging!\n",
    "        sent1, len1, sent2, len2, y = tuple(t.to(device) for t in batch_data) \n",
    "        probas = model(sent1, len1, sent2, len2)  # predict\n",
    "        \n",
    "        # back to CPU, back to numpy\n",
    "        probas = probas.cpu().detach().squeeze().numpy()\n",
    "        y = y.cpu().detach().numpy()\n",
    "                \n",
    "        # append\n",
    "        all_y = y if all_y is None else np.hstack((all_y, y))\n",
    "        all_probas = probas if all_probas is None else np.hstack((all_probas, probas))\n",
    "        \n",
    "        #if len(all_y) > 1000:\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     similar       0.50      0.30      0.37     21223\n",
      " not similar       0.77      0.88      0.82     56023\n",
      "\n",
      "    accuracy                           0.72     77246\n",
      "   macro avg       0.63      0.59      0.60     77246\n",
      "weighted avg       0.69      0.72      0.70     77246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t_max = 0.5  # classification threshold\n",
    "\n",
    "print(classification_report(all_y, np.where(all_probas > t_max, 1, 0), target_names=['similar', 'not similar']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9933501 , 0.27233917, 0.63532484, 0.98494476, 0.89609414,\n",
       "       0.97353697], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
